{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a 영역 대응점 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 13, RIGHT 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(587, 71), (589, 89), (597, 80), (603, 65), (591, 107), (599, 95), (607, 82), (614, 71), (621, 58), (592, 124), (601, 112), (606, 101), (615, 89), (623, 77), (630, 66), (639, 53), (593, 141), (602, 130), (611, 118), (619, 106)]\n",
      "이미지 2의 대응점들: [(178, 86), (183, 103), (189, 93), (197, 83), (185, 120), (192, 110), (199, 100), (205, 91), (213, 79), (188, 139), (196, 128), (203, 117), (209, 107), (216, 97), (223, 87), (228, 78), (192, 155), (198, 143), (205, 134), (211, 124)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L13.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R00.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 14, RIGHT 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(556, 75), (561, 92), (568, 79), (575, 67), (561, 106), (569, 97), (577, 86), (584, 75), (592, 64), (564, 126), (572, 115), (579, 102), (589, 93), (594, 80), (602, 70), (611, 58), (567, 142), (574, 131), (582, 122), (590, 111)]\n",
      "이미지 2의 대응점들: [(153, 84), (158, 101), (163, 91), (170, 82), (158, 120), (166, 109), (172, 101), (179, 89), (188, 79), (162, 137), (168, 128), (178, 118), (182, 108), (191, 97), (198, 88), (205, 76), (165, 155), (173, 145), (179, 134), (185, 124)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L14.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R01.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 15, RIGHT 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(537, 76), (538, 92), (548, 82), (554, 71), (540, 111), (548, 101), (554, 89), (564, 76), (570, 64), (543, 126), (551, 116), (556, 104), (564, 95), (572, 82), (579, 70), (587, 60), (544, 143), (552, 132), (559, 120), (567, 111)]\n",
      "이미지 2의 대응점들: [(129, 81), (132, 100), (140, 90), (148, 80), (136, 118), (144, 108), (151, 97), (158, 88), (165, 77), (140, 135), (146, 125), (152, 116), (160, 104), (168, 94), (175, 84), (180, 76), (143, 151), (149, 140), (157, 131), (164, 120)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L15.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R02.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 16, RIGHT 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(513, 76), (513, 94), (522, 83), (528, 72), (518, 112), (525, 101), (532, 90), (539, 78), (545, 68), (520, 126), (528, 116), (533, 107), (541, 95), (548, 84), (554, 74), (562, 61), (522, 144), (528, 134), (536, 122), (544, 112)]\n",
      "이미지 2의 대응점들: [(101, 77), (105, 97), (112, 85), (118, 76), (108, 115), (116, 104), (124, 94), (130, 84), (139, 73), (112, 132), (120, 121), (126, 112), (134, 101), (140, 91), (148, 80), (152, 72), (114, 149), (123, 138), (130, 129), (136, 120)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L16.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R03.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 17, RIGHT 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(488, 79), (490, 97), (497, 84), (504, 72), (492, 112), (498, 101), (505, 90), (515, 78), (520, 67), (493, 129), (500, 119), (507, 108), (514, 98), (520, 85), (528, 75), (536, 63), (496, 144), (503, 134), (508, 124), (516, 113)]\n",
      "이미지 2의 대응점들: [(73, 72), (77, 93), (84, 82), (94, 71), (83, 112), (88, 104), (97, 92), (105, 82), (113, 72), (86, 132), (92, 120), (100, 109), (107, 99), (114, 90), (120, 79), (128, 68), (89, 146), (96, 137), (103, 127), (109, 119)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L17.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R04.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 18, RIGHT 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(667, 20), (667, 37), (672, 28), (681, 20), (668, 52), (674, 43), (680, 35), (688, 28), (696, 17), (668, 68), (674, 59), (682, 52), (689, 43), (698, 33), (706, 25), (715, 14), (668, 82), (675, 75), (683, 67), (689, 59)]\n",
      "이미지 2의 대응점들: [(265, 54), (267, 68), (272, 61), (279, 53), (269, 82), (273, 76), (280, 70), (284, 63), (291, 56), (269, 95), (274, 89), (279, 84), (287, 76), (291, 70), (296, 64), (301, 58), (270, 110), (276, 104), (282, 98), (287, 93)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L18.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R05.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 19, RIGHT 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(656, 22), (655, 39), (662, 30), (668, 21), (655, 52), (662, 45), (668, 37), (676, 26), (684, 17), (653, 70), (663, 60), (668, 54), (676, 45), (684, 36), (693, 27), (699, 19), (655, 84), (660, 76), (668, 68), (677, 60)]\n",
      "이미지 2의 대응점들: [(240, 52), (242, 66), (246, 60), (252, 53), (244, 82), (248, 76), (253, 68), (258, 63), (264, 55), (244, 95), (249, 88), (254, 82), (260, 76), (266, 70), (272, 63), (276, 56), (244, 108), (249, 104), (253, 98), (259, 92)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L19.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R06.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 20, RIGHT 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(621, 28), (621, 41), (629, 35), (636, 26), (621, 59), (629, 50), (633, 42), (640, 34), (651, 24), (622, 72), (629, 65), (636, 57), (642, 51), (651, 41), (658, 30), (664, 24), (624, 88), (628, 80), (636, 73), (642, 66)]\n",
      "이미지 2의 대응점들: []\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L20.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R07.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 21, RIGHT 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(600, 30), (598, 45), (604, 37), (615, 28), (600, 60), (606, 52), (612, 44), (620, 36), (628, 25), (599, 75), (605, 69), (612, 61), (619, 52), (627, 44), (635, 36), (641, 24), (600, 90), (605, 83), (612, 76), (620, 68)]\n",
      "이미지 2의 대응점들: [(196, 49), (196, 62), (202, 57), (206, 50), (197, 76), (202, 72), (208, 64), (215, 58), (219, 51), (199, 92), (203, 86), (210, 79), (215, 72), (220, 66), (225, 60), (232, 53), (199, 105), (205, 100), (210, 95), (216, 88)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L21.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R08.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 22, RIGHT 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(572, 32), (572, 47), (578, 38), (586, 30), (572, 63), (578, 55), (585, 48), (592, 40), (598, 31), (573, 76), (579, 71), (586, 64), (591, 56), (599, 48), (603, 41), (615, 29), (573, 91), (578, 85), (586, 76), (592, 69)]\n",
      "이미지 2의 대응점들: [(172, 44), (172, 60), (179, 52), (185, 47), (174, 76), (179, 69), (185, 62), (191, 56), (196, 49), (175, 92), (180, 83), (186, 76), (192, 70), (198, 62), (203, 57), (209, 48), (175, 104), (180, 99), (188, 93), (192, 87)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L22.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R09.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
