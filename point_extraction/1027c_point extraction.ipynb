{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c 영역 대응점 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 13, RIGHT 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(688, 271), (686, 278), (684, 284), (684, 291), (683, 297), (703, 274), (700, 278), (700, 286), (700, 291), (697, 297)]\n",
      "이미지 2의 대응점들: [(274, 280), (273, 284), (271, 289), (270, 296), (269, 301), (287, 280), (286, 285), (283, 289), (283, 296), (283, 301)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L13.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R00.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 14, RIGHT 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(699, 237), (698, 224), (698, 212), (697, 199), (695, 183), (714, 232), (712, 219), (712, 206), (710, 192), (710, 178), (695, 340), (695, 334), (702, 249), (702, 256), (702, 260), (702, 266), (703, 273), (716, 245), (715, 249), (714, 256), (716, 261), (716, 267)]\n",
      "이미지 2의 대응점들: [(286, 250), (285, 237), (284, 226), (282, 214), (282, 200), (296, 244), (295, 233), (295, 222), (295, 210), (293, 198), (288, 259), (288, 265), (288, 271), (287, 274), (286, 280), (299, 254), (298, 261), (298, 264), (297, 269), (297, 275)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L14.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R01.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 15, RIGHT 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(700, 230), (698, 215), (697, 202), (697, 189), (696, 175), (706, 219), (706, 206), (706, 193), (705, 179), (702, 165), (689, 243), (689, 250), (689, 257), (689, 261), (689, 267), (704, 239), (703, 245), (703, 249), (703, 256), (705, 260)]\n",
      "이미지 2의 대응점들: [(286, 240), (285, 227), (285, 216), (284, 205), (283, 194), (292, 232), (291, 221), (290, 209), (289, 199), (287, 185), (281, 254), (279, 259), (279, 264), (279, 270), (278, 275), (289, 249), (290, 253), (289, 259), (290, 263), (290, 268)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L15.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R02.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 16, RIGHT 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(698, 220), (697, 207), (696, 193), (696, 180), (695, 166), (710, 213), (710, 200), (710, 188), (709, 174), (709, 162), (689, 234), (689, 240), (689, 244), (691, 250), (691, 255), (702, 229), (703, 234), (703, 239), (703, 245), (703, 250)]\n",
      "이미지 2의 대응점들: [(283, 231), (282, 220), (282, 210), (279, 198), (279, 185), (294, 227), (292, 218), (293, 205), (290, 195), (291, 183), (275, 245), (276, 251), (276, 253), (276, 257), (276, 261), (286, 243), (285, 246), (287, 250), (286, 253), (286, 257)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L16.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R03.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 17, RIGHT 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(679, 213), (678, 202), (677, 188), (676, 176), (676, 164), (691, 209), (690, 196), (689, 185), (688, 174), (689, 159), (695, 219), (696, 224), (696, 228), (696, 233), (696, 238), (707, 219), (709, 225), (709, 229), (711, 233), (709, 239)]\n",
      "이미지 2의 대응점들: [(271, 228), (271, 217), (270, 207), (269, 195), (269, 183), (281, 225), (281, 213), (280, 204), (278, 192), (281, 179), (285, 234), (287, 237), (287, 239), (287, 242), (287, 247), (295, 230), (296, 233), (296, 236), (296, 238), (295, 242)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L17.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R04.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 18, RIGHT 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(676, 212), (676, 200), (677, 186), (678, 175), (676, 161), (690, 213), (691, 199), (691, 187), (690, 174), (690, 163), (680, 224), (682, 229), (682, 233), (684, 238), (685, 242), (694, 228), (696, 231), (699, 237), (699, 242), (701, 246)]\n",
      "이미지 2의 대응점들: [(281, 224), (281, 212), (281, 203), (280, 190), (279, 180), (291, 227), (291, 217), (291, 206), (290, 194), (290, 184), (284, 235), (285, 239), (285, 243), (287, 249), (287, 253), (294, 240), (294, 244), (296, 247), (297, 249), (298, 252)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L18.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R05.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 19, RIGHT 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(692, 220), (693, 206), (691, 191), (690, 179), (692, 165), (707, 221), (705, 209), (709, 193), (706, 181), (707, 169), (682, 227), (682, 232), (685, 237), (687, 242), (687, 247), (696, 231), (696, 236), (698, 240), (700, 243), (702, 250)]\n",
      "이미지 2의 대응점들: [(277, 233), (277, 220), (277, 209), (276, 199), (275, 185), (289, 234), (287, 226), (287, 213), (289, 201), (288, 189), (271, 239), (271, 242), (271, 245), (271, 248), (271, 250), (281, 244), (281, 247), (281, 250), (281, 254), (284, 257)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L19.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R06.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 20, RIGHT 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(686, 225), (686, 212), (685, 197), (688, 186), (686, 173), (703, 230), (703, 215), (702, 203), (703, 189), (703, 174), (676, 235), (678, 239), (680, 244), (681, 249), (684, 254), (692, 239), (693, 246), (695, 249), (698, 253), (699, 258)]\n",
      "이미지 2의 대응점들: [(281, 237), (280, 228), (280, 215), (279, 203), (279, 192), (292, 240), (292, 228), (292, 218), (292, 207), (292, 195), (273, 245), (275, 249), (274, 253), (276, 257), (277, 261), (285, 250), (286, 253), (287, 257), (287, 262), (290, 266)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L20.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R07.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 21, RIGHT 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(661, 225), (661, 211), (664, 200), (663, 186), (663, 174), (676, 228), (677, 216), (677, 203), (675, 189), (679, 175), (653, 234), (654, 239), (656, 244), (657, 249), (659, 254), (668, 238), (671, 244), (674, 249), (675, 255), (676, 257)]\n",
      "이미지 2의 대응점들: [(257, 236), (257, 226), (257, 214), (256, 202), (254, 189), (267, 239), (267, 227), (267, 218), (268, 206), (269, 194), (249, 245), (250, 249), (251, 253), (251, 258), (252, 262), (261, 250), (260, 253), (261, 258), (262, 262), (264, 266)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L21.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R08.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 22, RIGHT 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(633, 225), (634, 213), (633, 200), (631, 187), (635, 174), (647, 230), (649, 217), (648, 205), (648, 192), (648, 177), (624, 235), (627, 241), (627, 243), (629, 248), (631, 252), (638, 239), (641, 242), (641, 247), (644, 252), (645, 258)]\n",
      "이미지 2의 대응점들: [(235, 239), (237, 227), (236, 215), (236, 202), (234, 191), (246, 239), (246, 227), (246, 216), (248, 207), (245, 192), (225, 246), (226, 250), (228, 253), (229, 258), (232, 263), (237, 250), (239, 255), (240, 259), (241, 262), (243, 268)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L22.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R09.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
