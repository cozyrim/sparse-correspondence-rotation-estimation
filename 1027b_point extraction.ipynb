{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b 영역 대응점 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 13, RIGHT 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(585, 71), (590, 91), (598, 77), (604, 65), (592, 107), (600, 94), (605, 84), (613, 73), (621, 60), (595, 124), (627, 288), (640, 296), (640, 290), (642, 284), (652, 302), (653, 297), (656, 292), (656, 287), (658, 279), (664, 311)]\n",
      "이미지 2의 대응점들: [(177, 86), (183, 104), (188, 94), (196, 84), (186, 122), (193, 112), (198, 103), (204, 92), (215, 80), (189, 140), (226, 296), (236, 304), (237, 298), (239, 290), (244, 308), (246, 303), (248, 296), (252, 289), (252, 284), (254, 314)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L13.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R00.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 14, RIGHT 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(557, 75), (561, 91), (568, 79), (576, 67), (564, 109), (571, 98), (580, 88), (584, 76), (592, 65), (566, 127), (599, 288), (610, 294), (610, 288), (614, 283), (622, 303), (624, 293), (625, 288), (627, 283), (629, 277), (636, 307)]\n",
      "이미지 2의 대응점들: [(154, 84), (156, 102), (164, 91), (173, 80), (160, 120), (167, 110), (176, 100), (183, 89), (188, 80), (163, 136), (200, 297), (209, 303), (211, 298), (213, 292), (220, 308), (221, 301), (223, 298), (226, 292), (229, 283), (231, 314)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L14.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R01.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 15, RIGHT 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(536, 76), (540, 93), (547, 81), (553, 70), (543, 110), (549, 97), (554, 89), (562, 78), (571, 66), (542, 126), (574, 288), (587, 295), (589, 287), (591, 280), (599, 301), (600, 294), (600, 288), (604, 282), (607, 275), (612, 306)]\n",
      "이미지 2의 대응점들: [(128, 80), (132, 104), (138, 92), (148, 82), (136, 116), (144, 108), (149, 98), (158, 89), (165, 76), (140, 135), (180, 296), (187, 304), (189, 297), (192, 292), (198, 308), (200, 304), (204, 298), (206, 292), (208, 284), (209, 314)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L15.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R02.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 16, RIGHT 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(514, 76), (515, 95), (523, 83), (531, 72), (518, 111), (524, 101), (531, 90), (538, 78), (546, 67), (519, 127), (551, 288), (562, 293), (565, 286), (567, 280), (572, 299), (575, 293), (577, 289), (580, 281), (580, 276), (585, 305)]\n",
      "이미지 2의 대응점들: [(98, 77), (103, 100), (112, 88), (120, 76), (108, 117), (115, 103), (123, 94), (130, 84), (138, 74), (112, 133), (150, 298), (160, 305), (164, 298), (166, 292), (172, 311), (174, 304), (175, 299), (178, 293), (179, 287), (184, 316)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L16.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R03.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 17, RIGHT 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(487, 80), (490, 97), (496, 85), (504, 74), (491, 113), (499, 101), (505, 91), (512, 79), (520, 68), (494, 131), (523, 285), (534, 295), (537, 287), (538, 280), (546, 300), (547, 293), (549, 287), (549, 281), (552, 275), (557, 305)]\n",
      "이미지 2의 대응점들: [(74, 75), (77, 95), (85, 83), (93, 71), (80, 114), (88, 103), (96, 93), (104, 84), (112, 70), (85, 130), (126, 299), (137, 306), (137, 300), (141, 293), (148, 311), (148, 304), (150, 300), (154, 294), (156, 285), (158, 317)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L17.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R04.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 18, RIGHT 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(453, 79), (456, 97), (463, 85), (470, 75), (457, 116), (464, 104), (474, 93), (478, 82), (485, 71), (461, 130), (492, 285), (500, 293), (502, 286), (504, 280), (511, 299), (514, 292), (516, 286), (518, 280), (518, 274), (523, 304)]\n",
      "이미지 2의 대응점들: [(46, 72), (50, 92), (60, 82), (67, 70), (56, 110), (64, 99), (71, 88), (77, 79), (87, 68), (57, 128), (100, 299), (110, 306), (114, 300), (118, 292), (121, 311), (125, 306), (126, 300), (129, 293), (132, 289), (135, 318)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L18.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R05.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 19, RIGHT 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(443, 81), (445, 99), (454, 86), (459, 76), (449, 114), (455, 104), (462, 93), (468, 82), (474, 71), (449, 130), (481, 286), (489, 292), (493, 286), (494, 279), (502, 298), (502, 291), (504, 286), (505, 281), (507, 275), (512, 303)]\n",
      "이미지 2의 대응점들: [(11, 69), (16, 87), (24, 78), (33, 65), (21, 107), (29, 94), (35, 87), (43, 75), (52, 63), (24, 124), (68, 302), (80, 309), (83, 301), (86, 292), (91, 313), (94, 305), (98, 300), (101, 293), (103, 286), (104, 318)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L19.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R06.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 20, RIGHT 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(620, 26), (621, 42), (628, 36), (636, 25), (621, 57), (629, 50), (635, 42), (642, 34), (649, 24), (622, 71), (453, 285), (462, 293), (464, 287), (466, 279), (472, 299), (474, 293), (475, 286), (479, 282), (480, 274), (483, 303)]\n",
      "이미지 2의 대응점들: [(220, 51), (220, 64), (226, 59), (232, 52), (223, 79), (228, 73), (233, 67), (238, 60), (245, 53), (223, 93), (44, 301), (57, 308), (60, 301), (62, 295), (68, 313), (70, 307), (75, 301), (76, 294), (79, 288), (81, 320)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L20.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R07.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 21, RIGHT 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(598, 30), (599, 45), (606, 37), (612, 28), (598, 60), (605, 52), (612, 45), (619, 36), (626, 27), (599, 75), (435, 287), (442, 291), (446, 286), (448, 279), (454, 297), (456, 291), (457, 286), (459, 281), (461, 274), (464, 302)]\n",
      "이미지 2의 대응점들: [(193, 47), (194, 62), (201, 58), (207, 49), (196, 76), (201, 72), (207, 64), (212, 60), (219, 53), (198, 92), (11, 302), (23, 311), (28, 302), (32, 296), (36, 316), (39, 309), (41, 301), (45, 296), (46, 291), (49, 321)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L21.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R08.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEFT 22, RIGHT 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 1에서 대응점을 선택하세요.\n",
      "이미지 2에서 대응점을 선택하세요.\n",
      "이미지 1의 대응점들: [(571, 32), (572, 48), (578, 40), (585, 32), (572, 62), (579, 56), (585, 49), (590, 39), (598, 31), (572, 76), (624, 236), (624, 240), (626, 242), (627, 249), (631, 255), (639, 238), (641, 244), (641, 246), (644, 253), (646, 259)]\n",
      "이미지 2의 대응점들: [(171, 45), (172, 60), (177, 55), (184, 48), (174, 77), (179, 68), (184, 64), (189, 55), (197, 49), (174, 90), (226, 245), (227, 251), (228, 253), (229, 256), (229, 263), (239, 251), (239, 254), (240, 257), (241, 262), (244, 268)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def select_points(img):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.imshow('image', img)\n",
    "\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.setMouseCallback('image', click_event)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return points\n",
    "\n",
    "# 이미지 로드\n",
    "img1 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_L22.png')\n",
    "img2 = cv2.imread('C:/Users/chaerim/OneDrive/Calibration/matching/matching/images/dog_edges_R09.png')\n",
    "\n",
    "print(\"이미지 1에서 대응점을 선택하세요.\")\n",
    "ground_truth_points1 = select_points(img1)\n",
    "\n",
    "print(\"이미지 2에서 대응점을 선택하세요.\")\n",
    "ground_truth_points2 = select_points(img2)\n",
    "\n",
    "print(\"이미지 1의 대응점들:\", ground_truth_points1)\n",
    "print(\"이미지 2의 대응점들:\", ground_truth_points2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
